<!DOCTYPE html>
<html>
<head>
    <title>Live Camera Feed</title>
</head>
<body>
    <h1>Live Camera Feed</h1>
    <button id="start-camera">Start Camera</button>
    <video id="video" width="640" height="480" autoplay style="display: none;"></video>
    <div id="result"></div>
    <div id="translated-result"></div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script>
        const startCameraButton = document.getElementById('start-camera');
        const video = document.getElementById('video');
        const resultDiv = document.getElementById('result');
        const translatedResultDiv = document.getElementById('translated-result');
        let camera;

        const hands = new Hands({locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
        }});

        hands.setOptions({
            maxNumHands: 2,
            modelComplexity: 1,
            minDetectionConfidence: 0.7,  // Increased detection confidence
            minTrackingConfidence: 0.7   // Increased tracking confidence
        });

        hands.onResults(onResults);

        startCameraButton.addEventListener('click', () => {
            video.style.display = 'block';
            camera = new Camera(video, {
                onFrame: async () => {
                    await hands.send({image: video});
                },
                width: 640,
                height: 480
            });

            camera.start();
        });

        function onResults(results) {
            // Check if any hands are detected
            if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
                captureImage();
            }
        }

        function captureImage() {
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            const context = canvas.getContext('2d');
            context.drawImage(video, 0, 0, canvas.width, canvas.height);
            const dataUrl = canvas.toDataURL('image/png');

            fetch('/upload', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/x-www-form-urlencoded'
                },
                body: `image=${encodeURIComponent(dataUrl)}`
            })
            .then(response => response.json())
            .then(data => {
                // Display the word and its translation received from the backend
                resultDiv.innerText = `Detected word: ${data.word}`;
                translatedResultDiv.innerText = `Translated to Maori: ${data.translated_word}`;
            })
            .catch(error => {
                console.error('Error:', error);
            });
        }
    </script>
</body>
</html>
